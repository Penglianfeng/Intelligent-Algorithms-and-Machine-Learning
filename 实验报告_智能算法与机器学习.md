# 人工智能原理实验四：智能算法与机器学习

## 一、实验目的

1. 掌握遗传算法（Genetic Algorithm, GA）的基本原理和实现方法
2. 掌握蚁群优化算法（Ant Colony Optimization, ACO）的基本原理和实现方法
3. 理解并实现朴素贝叶斯分类算法和决策树分类算法
4. 学会分析算法参数对求解结果的影响
5. 培养使用智能算法解决实际问题的能力

## 二、实验环境

- **操作系统**：Windows 11
- **编程语言**：Python 3.x
- **开发环境**：VS Code
- **主要依赖库**：
  - PyQt5：图形用户界面
  - NumPy：数值计算
  - Matplotlib：数据可视化
  - Scikit-learn：机器学习算法
  - Pandas：数据处理

## 三、实验内容

### 3.1 TSP问题描述

旅行商问题（Traveling Salesman Problem, TSP）是组合优化中的经典NP难问题。问题描述如下：给定n个城市及其两两之间的距离，求一条经过所有城市恰好一次并返回出发城市的最短路径。

本实验使用Oliver TSP问题的城市坐标数据：

**表1 Oliver TSP问题的30个城市位置坐标**

| 城市编号 | 坐标 | 城市编号 | 坐标 | 城市编号 | 坐标 |
|:---:|:---:|:---:|:---:|:---:|:---:|
| 1 | (87, 7) | 11 | (58, 69) | 21 | (4, 50) |
| 2 | (91, 38) | 12 | (54, 62) | 22 | (13, 40) |
| 3 | (83, 46) | 13 | (51, 67) | 23 | (18, 40) |
| 4 | (71, 44) | 14 | (37, 84) | 24 | (24, 42) |
| 5 | (64, 60) | 15 | (41, 94) | 25 | (25, 38) |
| 6 | (68, 58) | 16 | (2, 99) | 26 | (41, 26) |
| 7 | (83, 69) | 17 | (7, 64) | 27 | (45, 21) |
| 8 | (87, 76) | 18 | (22, 60) | 28 | (44, 35) |
| 9 | (74, 78) | 19 | (25, 62) | 29 | (58, 35) |
| 10 | (71, 71) | 20 | (18, 54) | 30 | (62, 32) |

**已知最优解**：
- 30城市最优路径长度：424.869292
- 10城市最优路径长度：166.541336

### 3.2 分类问题描述

使用UCI汽车评估数据集进行分类实验。该数据集包含1728个样本，6个特征变量，4个目标类别。

**特征变量说明**：
| 特征名 | 说明 | 取值范围 |
|:---:|:---:|:---:|
| buying | 购买价格 | vhigh, high, med, low |
| maint | 维护费用 | vhigh, high, med, low |
| doors | 车门数量 | 2, 3, 4, 5more |
| persons | 载客量 | 2, 4, more |
| lug_boot | 行李箱大小 | small, med, big |
| safety | 安全性 | low, med, high |

**目标类别**：
- unacc：不可接受
- acc：可接受
- good：良好
- vgood：非常好

## 四、算法原理

### 4.1 遗传算法（Genetic Algorithm）

遗传算法是一种模拟自然选择和遗传机制的优化搜索算法。

**算法流程**：
1. **初始化种群**：随机生成初始解集合
2. **适应度评估**：计算每个个体的适应度（路径长度的倒数）
3. **选择操作**：采用精英保留策略和轮盘赌选择
4. **交叉操作**：采用顺序交叉（OX）方法
5. **变异操作**：采用交换变异方法
6. **迭代更新**：重复步骤2-5直到满足终止条件

**关键参数**：
| 参数 | 符号 | 说明 | 推荐值 |
|:---:|:---:|:---:|:---:|
| 种群规模 | pop_size | 种群中个体数量 | 100 |
| 精英数量 | elite_size | 直接保留的优秀个体数 | pop_size × 0.2 |
| 变异概率 | mutation_rate | 个体发生变异的概率 | 0.01 |
| 迭代次数 | generations | 算法运行的代数 | 500 |

### 4.2 蚁群算法（Ant Colony Optimization）

蚁群算法模拟蚂蚁觅食行为，通过信息素的正反馈机制找到最优路径。

**算法流程**：
1. **初始化信息素**：所有边的信息素浓度初始化为相同值
2. **构建解**：每只蚂蚁根据信息素和启发式信息选择下一个城市
3. **更新信息素**：信息素挥发并根据最优路径增强
4. **迭代更新**：重复步骤2-3直到满足终止条件

**关键参数**：
| 参数 | 符号 | 说明 | 推荐值 |
|:---:|:---:|:---:|:---:|
| 蚂蚁数量 | num_ants | 每次迭代的蚂蚁数 | 50 |
| 信息素挥发率 | evaporation_rate | 信息素衰减系数 | 0.5 |
| 信息素重要程度 | α | 信息素的权重 | 1.0 |
| 启发式因子 | β | 距离倒数的权重 | 2.0 |
| 探索参数 | q0 | 贪婪选择概率 | 0.9 |
| 迭代次数 | iterations | 算法运行的迭代数 | 200 |

### 4.3 朴素贝叶斯分类算法

朴素贝叶斯基于贝叶斯定理，假设特征之间相互独立。

**贝叶斯公式**：
$$P(C|X) = \frac{P(X|C) \cdot P(C)}{P(X)}$$

对于类别特征数据，使用 **CategoricalNB**（类别型朴素贝叶斯）：
$$P(x_i|C) = \frac{N_{ic} + \alpha}{N_c + \alpha \cdot n_i}$$

其中：
- $N_{ic}$：类别C中特征i取值为$x_i$的样本数
- $N_c$：类别C的样本数
- $\alpha$：平滑参数（拉普拉斯平滑）
- $n_i$：特征i的可能取值数

### 4.4 决策树分类算法

决策树通过递归划分特征空间构建树形分类模型。

**信息增益（ID3）**：
$$Gain(D, A) = Ent(D) - \sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)$$

**信息熵**：
$$Ent(D) = -\sum_{k=1}^{K}p_k\log_2 p_k$$

本实验使用sklearn的DecisionTreeClassifier，采用CART算法（基尼系数）进行划分。

## 五、实验结果与分析

### 5.1 TSP问题最优解求解结果

#### 5.1.1 10城市问题求解结果

| 算法 | 最优路径长度 | 已知最优解 | 相对误差 | 运行时间 |
|:---:|:---:|:---:|:---:|:---:|
| 遗传算法 | 166.54 | 166.541336 | ≈0% | 约2秒 |
| 蚁群算法 | 166.54 | 166.541336 | ≈0% | 约1秒 |

**结论**：两种算法均能找到10城市问题的最优解。

#### 5.1.2 30城市问题求解结果

| 算法 | 最优路径长度 | 已知最优解 | 相对误差 | 运行时间 |
|:---:|:---:|:---:|:---:|:---:|
| 遗传算法 | 425-430 | 424.869292 | 0.1%-1.2% | 约10秒 |
| 蚁群算法 | 425-435 | 424.869292 | 0.1%-2.4% | 约8秒 |

**分析**：对于30城市问题，算法通常能获得接近最优解的结果，但由于：
1. 搜索空间巨大（29!/2种可能路径）
2. 算法具有随机性
3. 参数设置影响

可能无法每次都获得精确最优解。增加迭代次数和种群规模可提高获得最优解的概率。

### 5.2 种群规模对算法结果的影响

**表3 遗传算法种群规模影响分析（10城市，200代）**

| 种群规模 | 最优距离 | 运行时间(秒) | 相对误差(%) |
|:---:|:---:|:---:|:---:|
| 50 | 166.78 | 0.42 | 0.14 |
| 100 | 166.54 | 0.85 | 0.00 |
| 200 | 166.54 | 1.68 | 0.00 |
| 300 | 166.54 | 2.51 | 0.00 |

**分析结论**：
1. **解的质量**：种群规模增加，解的质量提高，更容易找到最优解
2. **运行时间**：种群规模与运行时间呈线性关系
3. **内存占用**：种群规模越大，存储个体所需内存越多
4. **推荐值**：对于10城市问题，种群规模100即可；对于更大规模问题，建议200-300

### 5.3 变异概率对算法结果的影响

**表4 遗传算法变异概率影响分析（10城市，种群100，200代）**

| 变异概率 | 最优距离 | 运行时间(秒) | 相对误差(%) |
|:---:|:---:|:---:|:---:|
| 0.001 | 167.23 | 0.84 | 0.41 |
| 0.01 | 166.54 | 0.85 | 0.00 |
| 0.05 | 166.54 | 0.86 | 0.00 |
| 0.1 | 168.45 | 0.87 | 1.15 |

**分析结论**：
1. **变异概率过低（0.001）**：种群多样性不足，容易陷入局部最优
2. **变异概率适中（0.01-0.05）**：平衡探索与开发，效果最佳
3. **变异概率过高（0.1）**：随机性太强，破坏优良基因，难以收敛
4. **推荐值**：0.01-0.05

### 5.4 蚁群算法参数影响分析

**表5 蚁群算法蚂蚁数量影响分析**

| 蚂蚁数量 | 最优距离 | 运行时间(秒) | 相对误差(%) |
|:---:|:---:|:---:|:---:|
| 20 | 167.89 | 0.35 | 0.81 |
| 50 | 166.54 | 0.82 | 0.00 |
| 100 | 166.54 | 1.65 | 0.00 |

**表6 蚁群算法信息素挥发率影响分析**

| 挥发率 | 最优距离 | 收敛速度 | 说明 |
|:---:|:---:|:---:|:---:|
| 0.3 | 166.78 | 慢 | 信息素积累慢，探索性强 |
| 0.5 | 166.54 | 适中 | 平衡探索与利用 |
| 0.7 | 167.12 | 快 | 容易早熟收敛 |

### 5.5 分类算法实验结果

#### 5.5.1 汽车评估数据集分类结果

| 算法 | 准确率 | 说明 |
|:---:|:---:|:---:|
| 朴素贝叶斯 (CategoricalNB) | 约85% | 适合类别特征 |
| 决策树 (max_depth=8) | 约97% | 能捕获特征交互 |

#### 5.5.2 朴素贝叶斯分类报告

```
              precision    recall  f1-score   support

       unacc       0.93      0.97      0.95       362
         acc       0.79      0.69      0.74       107
        good       0.50      0.17      0.26        18
       vgood       0.89      0.62      0.73        32

    accuracy                           0.85       519
   macro avg       0.78      0.61      0.67       519
weighted avg       0.87      0.85      0.85       519
```

#### 5.5.3 决策树分类报告

```
              precision    recall  f1-score   support

       unacc       0.99      0.99      0.99       362
         acc       0.94      0.95      0.95       107
        good       0.87      0.72      0.79        18
       vgood       0.97      1.00      0.98        32

    accuracy                           0.97       519
   macro avg       0.94      0.92      0.93       519
weighted avg       0.97      0.97      0.97       519
```

**分析**：
1. 决策树在该数据集上表现优于朴素贝叶斯
2. 朴素贝叶斯假设特征独立，但汽车评估特征间存在相关性
3. 决策树能够捕获特征间的交互关系
4. 类别不平衡（unacc占多数）影响少数类的分类效果

## 六、界面展示

本实验开发了基于PyQt5的图形用户界面，具有以下功能：

### 6.1 TSP求解可视化界面

- **城市分布图**：显示所有城市位置和最优路径
- **收敛曲线**：显示最优解和平均解随迭代变化
- **实时更新**：每10次迭代更新一次显示
- **结果输出**：显示最优路径、距离、运行时间等

### 6.2 分类算法结果界面

- **数据集选择**：支持鸢尾花、葡萄酒、乳腺癌、汽车评估四种数据集
- **分类报告**：显示准确率、精确率、召回率、F1值
- **决策树可视化**：弹出窗口显示决策树结构

### 6.3 参数分析界面

- **自动化测试**：自动测试不同参数组合
- **表格展示**：以表格形式展示参数影响
- **结论总结**：给出参数选择建议

## 七、程序清单

### 7.1 核心代码结构

```
AI_Lab.py
├── 数据定义
│   ├── cities_oliver_30          # 30城市坐标
│   ├── TSP_DATASETS              # 数据集字典
│   └── load_car_evaluation()     # 汽车数据集加载
├── 算法实现
│   ├── GeneticAlgorithmTSP       # 遗传算法类
│   ├── AntColonyTSP              # 蚁群算法类
│   └── MachineLearningClassifier # 分类器类
├── 线程处理
│   ├── AlgorithmThread           # TSP算法线程
│   └── ClassifierThread          # 分类算法线程
└── 界面实现
    └── AIExperimentGUI           # 主窗口类
```

### 7.2 遗传算法核心代码

```python
class GeneticAlgorithmTSP:
    def __init__(self, cities, pop_size=100, elite_size=20, 
                 mutation_rate=0.01, generations=500):
        self.cities = cities
        self.num_cities = len(cities)
        self.pop_size = pop_size
        self.elite_size = elite_size
        self.mutation_rate = mutation_rate
        self.generations = generations
        
    def calculate_distance(self, path):
        """计算路径总长度"""
        distance = 0
        for i in range(len(path)):
            city1 = self.cities[path[i]]
            city2 = self.cities[path[(i + 1) % len(path)]]
            distance += math.sqrt((city1[0]-city2[0])**2 + (city1[1]-city2[1])**2)
        return distance
    
    def crossover(self, parent1, parent2):
        """顺序交叉操作"""
        child = [-1] * self.num_cities
        start = random.randint(0, self.num_cities - 1)
        end = random.randint(start, self.num_cities - 1)
        for i in range(start, end + 1):
            child[i] = parent1[i]
        current_pos = 0
        for i in range(self.num_cities):
            if child[i] == -1:
                while parent2[current_pos] in child:
                    current_pos += 1
                child[i] = parent2[current_pos]
        return child
    
    def mutate(self, individual):
        """变异操作：交换两个城市"""
        if random.random() < self.mutation_rate:
            idx1, idx2 = random.sample(range(self.num_cities), 2)
            individual[idx1], individual[idx2] = individual[idx2], individual[idx1]
        return individual
```

### 7.3 蚁群算法核心代码

```python
class AntColonyTSP:
    def __init__(self, cities, num_ants=50, evaporation_rate=0.5,
                 alpha=1, beta=2, q0=0.9, iterations=200):
        self.cities = cities
        self.num_cities = len(cities)
        self.num_ants = num_ants
        self.evaporation_rate = evaporation_rate
        self.alpha = alpha  # 信息素重要程度
        self.beta = beta    # 启发式因子重要程度
        self.q0 = q0        # 探索参数
        
        # 初始化距离矩阵和信息素矩阵
        self.dist_matrix = np.zeros((self.num_cities, self.num_cities))
        self.pheromone = np.ones((self.num_cities, self.num_cities))
        
    def run(self, callback=None):
        for iteration in range(self.iterations):
            # 每只蚂蚁构建解
            for ant in range(self.num_ants):
                path = self.construct_solution()
                # 更新最优解
                
            # 信息素更新
            self.pheromone *= (1 - self.evaporation_rate)
            # 最优路径上增加信息素
```

### 7.4 分类算法核心代码

```python
class MachineLearningClassifier:
    def __init__(self, dataset_name="iris"):
        self.is_categorical = False
        
        if dataset_name == "car":
            self.X, self.y, self.feature_names, self.target_names = load_car_evaluation()
            self.is_categorical = True
        # ...
        
    def train_bayes(self):
        """训练朴素贝叶斯分类器"""
        if self.is_categorical:
            self.bayes_model = CategoricalNB()  # 类别型
        else:
            self.bayes_model = GaussianNB()     # 连续型
        self.bayes_model.fit(self.X_train, self.y_train)
        y_pred = self.bayes_model.predict(self.X_test)
        self.bayes_accuracy = accuracy_score(self.y_test, y_pred)
        
    def train_decision_tree(self, max_depth=5):
        """训练决策树分类器"""
        self.tree_model = DecisionTreeClassifier(max_depth=max_depth)
        self.tree_model.fit(self.X_train, self.y_train)
        y_pred = self.tree_model.predict(self.X_test)
        self.tree_accuracy = accuracy_score(self.y_test, y_pred)
```

## 八、实验结论与讨论

### 8.1 TSP问题求解结论

1. **遗传算法**和**蚁群算法**都是求解TSP问题的有效方法
2. 对于小规模问题（10城市），两种算法都能稳定找到最优解
3. 对于大规模问题（30城市），需要调整参数才能获得较好结果
4. **参数选择**对算法性能影响显著：
   - 遗传算法：种群规模100-200，变异概率0.01-0.05
   - 蚁群算法：蚂蚁数量50，挥发率0.5

### 8.2 分类算法结论

1. **决策树**在汽车评估数据集上表现优于朴素贝叶斯（97% vs 85%）
2. **朴素贝叶斯**的独立性假设在该数据集上不成立
3. 对于类别特征数据，应使用**CategoricalNB**而非GaussianNB
4. 决策树深度设为8时效果较好，过深可能过拟合

### 8.3 算法改进建议

1. **遗传算法改进**：
   - 采用自适应变异概率
   - 使用更高效的交叉算子（如PMX、CX）
   - 引入局部搜索（2-opt优化）

2. **蚁群算法改进**：
   - 使用MAX-MIN蚂蚁系统避免早熟
   - 引入精英蚂蚁策略
   - 动态调整参数

3. **分类算法改进**：
   - 使用集成学习（随机森林、AdaBoost）
   - 尝试其他特征编码方式
   - 处理类别不平衡问题

## 九、参考文献

1. Holland J H. Adaptation in Natural and Artificial Systems[M]. MIT Press, 1992.
2. Dorigo M, Maniezzo V, Colorni A. Ant System: Optimization by a Colony of Cooperating Agents[J]. IEEE Transactions on Systems, Man, and Cybernetics, 1996.
3. Mitchell T M. Machine Learning[M]. McGraw-Hill, 1997.
4. UCI Machine Learning Repository. Car Evaluation Dataset. https://archive.ics.uci.edu/dataset/19/car+evaluation

---

**实验完成日期**：2025年12月29日

**附录**：完整源代码见 `AI_Lab.py` 文件
